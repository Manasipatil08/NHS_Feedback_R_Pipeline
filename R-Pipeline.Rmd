title: "NHS_Feedback_R-Pipeline_Model Tunning"
author: "Manasi Patil"
date: "2025-08-14" 
output: html_document

```{r}
# knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# # Create directories for saving outputs
# dir.create("plots", showWarnings = FALSE)
# dir.create("results", showWarnings = FALSE)
```

```{r Load Libraries}
# 
# #Load R packages for text analysis, modeling, visualization, and Shiny app development.
# 
# library(ggraph)
# library(glmnet)
# library(here)
# library(igraph)
# library(textrecipes)
# library(tidymodels)
# library(tidytext)
# library(tidyverse)
# library(tm)
# library(topicmodels)
# library(wordcloud)
# library(viridis)
# library(stringr)
# library(parsnip)
# library(ranger)
# library(naivebayes)
# library(yardstick)
# library(pROC)
# library(caret)
# library(xgboost)
# library(ggplot2)
# library(discrim)
# library(tune)
# library(dplyr)
# library(shiny)
# library(vip)
# library(RColorBrewer)
# set.seed(123)
# ```
# 
# ```{r Load Data}
# 
# #Load the NHS feedback dataset and add an ID column for document tracking.
# 
# feedback <- read_csv(file = here("data", "updated_feedback.csv")) %>%
#   mutate(ID = row_number())  # Add ID for document-level tracking
# 
# # Error handling: Check for required columns
# if (!"Clinical.Y.N" %in% colnames(feedback)) {
#   stop("Clinical.Y.N column not found in dataset.")
# }
# if (any(is.na(feedback$Clinical.Y.N))) {
#   warning("Missing values in Clinical.Y.N. Imputing with 'No'.")
#   feedback$Clinical.Y.N[is.na(feedback$Clinical.Y.N)] <- "No"
# }
# # Check dataset structure
# str(feedback)
# ```
# 
# ```{r Data Preprocessing and Cleaning}
# 
# #Clean feedback text, retaining ID and other columns for group analysis.
# 
# cleaned_data <- feedback %>%
#   mutate(Feedback = str_replace_all(Feedback, "[^[:alnum:] ]", "")) %>% 
#   unnest_tokens(word, Feedback, drop = FALSE) %>%  # Keep ID, Clinical.Y.N, etc.
#   anti_join(stop_words, by = "word")              # Remove stopwords
# 
# ```
# 
# ```{r Exploratory Data Analysis}
# 
# #Word Cloud
# 
# #Visualize frequent words using a word cloud.
# 
# wordcloud(words = cleaned_data$word, 
#           min.freq = 3, 
#           max.words = 150, 
#           random.order = FALSE, 
#           colors = viridis(100))
# ```
# 
# ```{r Most Frequent Words}
# #Plot the top 20 most frequent words.
# 
# word_freq <- cleaned_data %>%
#   count(word, sort = TRUE)
# 
# ggplot(word_freq[1:20, ], aes(x = reorder(word, n), y = n)) +
#   geom_bar(stat = "identity", fill = "lightblue") +
#   coord_flip() +
#   labs(title = "Top 20 Most Frequent Words in Feedback", 
#        x = "Word", y = "Frequency") +
#   theme_minimal()
# ```
# 
# ```{r Sentiment Analysis}
# 
# #Bing Sentiment Lexicon
# 
# #Analyze sentiment using the Bing lexicon.
# 
# bing <- cleaned_data %>%
#   inner_join(get_sentiments("bing"), by = "word")
# 
# bing_count <- bing %>%
#   count(sentiment, sort = TRUE)
# 
# ggplot(bing_count, aes(x = sentiment, y = n, fill = sentiment)) +
#   geom_col(show.legend = FALSE) +
#   labs(title = "Sentiment Counts from NHS Feedback",
#        x = "Sentiment", y = "Count") +
#   theme_minimal()
# 
# # Top 20 positive and negative words
# bing %>%
#   filter(sentiment == "positive") %>%
#   count(word, sort = TRUE) %>%
#   head(20)
# 
# bing %>%
#   filter(sentiment == "negative") %>%
#   count(word, sort = TRUE) %>%
#   head(20)
# 
# #NRC Sentiment Lexicon
# 
# #Analyze emotions using the NRC lexicon.
# 
# nrc <- cleaned_data %>%
#   inner_join(get_sentiments("nrc"), by = "word")
# 
# nrc_count <- nrc %>%
#   count(sentiment, sort = TRUE)
# 
# nrc_count %>%
#   filter(!sentiment %in% c("positive", "negative")) %>%
#   ggplot(aes(x = reorder(sentiment, n), y = n, fill = sentiment)) +
#   geom_col(show.legend = FALSE) +
#   coord_flip() +
#   labs(title = "Emotion Distribution in Feedback (NRC)",
#        x = "Emotion", y = "Count") +
#   theme_minimal()
# 
# #AFINN Sentiment Lexicon
# 
# #Analyze sentiment scores using the AFINN lexicon.
# 
# afinn <- cleaned_data %>%
#   inner_join(get_sentiments("afinn"), by = "word")
# 
# afinn_count <- afinn %>%
#   count(value, sort = TRUE)
# 
# ggplot(afinn, aes(x = reorder(word, value), y = value, fill = value > 0)) +
#   geom_col(show.legend = FALSE) +
#   coord_flip() +
#   labs(
#     title = "Sentiment Scores from AFINN (NHS Feedback Words)",
#     x = "Word",
#     y = "Sentiment Score"
#   ) +
#   scale_fill_manual(values = c("red", "steelblue")) +
#   theme_minimal()
# 
# ```
# 
# ```{r Group Analysis: Clinical.Y.N and Gender}
# 
# #Compare word frequency, sentiment, and topic distribution between Clinical.Y.N ("Yes" vs. "No") and Gender ("Male" vs. "Female") groups.
# 
# # Word Frequency by Clinical.Y.N
# word_freq_by_clinical <- cleaned_data %>%
#   count(Clinical.Y.N, word, sort = TRUE) %>%
#   group_by(Clinical.Y.N) %>%
#   mutate(proportion = n / sum(n)) %>%
#   ungroup() %>%
#   pivot_wider(names_from = Clinical.Y.N, values_from = proportion, values_fill = 0) %>%
#   mutate(diff = Y - N) %>%
#   arrange(desc(abs(diff)))
# 
# # Plot top 10 words with largest frequency differences
# word_freq_by_clinical %>%
#   slice_head(n = 10) %>%
#   ggplot(aes(x = reorder(word, diff), y = diff, fill = diff > 0)) +
#   geom_col(show.legend = FALSE) +
#   coord_flip() +
#   labs(
#     title = "Words with Largest Frequency Differences: Clinical vs. Non-Clinical",
#     x = "Word",
#     y = "Difference in Proportion (Yes - No)"
#   ) +
#   scale_fill_manual(values = c("red", "blue")) +
#   theme_minimal()
# 
# # Sentiment by Clinical.Y.N (Bing)
# bing_by_clinical <- cleaned_data %>%
#   inner_join(get_sentiments("bing"), by = "word") %>%
#   count(Clinical.Y.N, sentiment) %>%
#   group_by(Clinical.Y.N) %>%
#   mutate(proportion = n / sum(n)) %>%
#   ungroup()
# 
# ggplot(bing_by_clinical, aes(x = Clinical.Y.N, y = proportion, fill = sentiment)) +
#   geom_col(position = "dodge") +
#   labs(
#     title = "Sentiment Distribution by Clinical vs. Non-Clinical Feedback",
#     x = "Clinical Status",
#     y = "Proportion"
#   ) +
#   scale_fill_manual(values = c("negative" = "red", "positive" = "blue")) +
#   theme_minimal()
# 
# # Word Frequency by Gender (if available)
# if ("Gender" %in% colnames(feedback)) {
#   word_freq_by_gender <- cleaned_data %>%
#     count(Gender, word, sort = TRUE) %>%
#     group_by(Gender) %>%
#     mutate(proportion = n / sum(n)) %>%
#     ungroup() %>%
#     pivot_wider(names_from = Gender, values_from = proportion, values_fill = 0) %>%
#     mutate(diff = M - F) %>%
#     arrange(desc(abs(diff)))
# 
#   word_freq_by_gender %>%
#     slice_head(n = 10) %>%
#     ggplot(aes(x = reorder(word, diff), y = diff, fill = diff > 0)) +
#     geom_col(show.legend = FALSE) +
#     coord_flip() +
#     labs(
#       title = "Words with Largest Frequency Differences: Male vs. Female",
#       x = "Word",
#       y = "Difference in Proportion (Male - Female)"
#     ) +
#     scale_fill_manual(values = c("red", "blue")) +
#     theme_minimal()
# 
#   # Sentiment by Gender (Bing)
#   bing_by_gender <- cleaned_data %>%
#     inner_join(get_sentiments("bing"), by = "word") %>%
#     count(Gender, sentiment) %>%
#     group_by(Gender) %>%
#     mutate(proportion = n / sum(n)) %>%
#     ungroup()
# 
#   ggplot(bing_by_gender, aes(x = Gender, y = proportion, fill = sentiment)) +
#     geom_col(position = "dodge") +
#     labs(
#       title = "Sentiment Distribution by Gender",
#       x = "Gender",
#       y = "Proportion"
#     ) +
#     scale_fill_manual(values = c("negative" = "red", "positive" = "blue")) +
#     theme_minimal()
```

```{r Term Frequency}

# #Visualize term frequency after initial cleaning.
# 
# term_freq <- cleaned_data %>%
#   count(word, sort = TRUE)
# 
# wordcloud(words = term_freq$word,
#           freq = term_freq$n,
#           max.words = 100,
#           colors = brewer.pal(8, "Dark2"))
# 
# #Removing Stop Words Manually
# 
# #Remove custom stopwords and visualize updated term frequency.
# 
# cleaned_data <- cleaned_data %>%
#   filter(!word %in% c("ive", "im", "whats"))
# 
# clean_term_freq <- cleaned_data %>%
#   count(word, sort = TRUE)
# 
# wordcloud(words = clean_term_freq$word,
#           freq = clean_term_freq$n,
#           max.words = 100,
#           colors = brewer.pal(8, "Dark2"))
# 
# ggplot(clean_term_freq %>% slice_max(n, n = 20) %>% arrange(n),
#        aes(x = reorder(word, n), y = n)) +
#   geom_col(fill = "pink") +
#   coord_flip() +
#   labs(
#     title = "Top 20 Most Frequent Words in NHS Feedback",
#     x = "Word",
#     y = "Frequency"
#   ) +
#   theme_minimal()
# 
# ```
# 
# ```{r Reconstructing the Feedback }
# # Clean feedback further, retaining ID.
# 
# feedback_cleaned <- feedback %>%
#   mutate(Feedback = str_replace_all(Feedback, "[^[:alnum:] ]", "")) %>%
#   mutate(Feedback = str_to_lower(Feedback)) %>%
#   mutate(Feedback = removeWords(Feedback, stopwords("en"))) %>%
#   mutate(Feedback = str_replace_all(Feedback, "\\b(ive|im|whats|i|wont|theyve)\\b", "")) %>%
#   mutate(Feedback = str_squish(Feedback))
# ```
# 
# ``` {r TF-IDF}
# 
# #Compute TF-IDF scores using the ID column from feedback_cleaned.
# 
# cleaned_tokens <- feedback_cleaned %>%
#   unnest_tokens(word, Feedback, drop = FALSE) %>%  # Retain ID
#   anti_join(stop_words, by = "word")
# 
# tfidf <- cleaned_tokens %>%
#   count(ID, word, sort = TRUE) %>%
#   bind_tf_idf(word, ID, n) %>%
#   arrange(desc(tf_idf))
# 
# tfidf %>%
#   group_by(word) %>%
#   slice_max(tf_idf, n = 1) %>%
#   ungroup() %>%
#   slice_max(tf_idf, n = 20) %>%
#   ggplot(aes(x = reorder(word, tf_idf), y = tf_idf, fill = tf_idf)) +
#   geom_col(show.legend = FALSE) +
#   coord_flip() +
#   scale_fill_gradient(low = "#b3cde3", high = "#011f4b") +
#   labs(
#     title = "Top 20 TF-IDF Words",
#     x = "Words",
#     y = "TF-IDF Score"
#   ) +
#   theme_minimal(base_size = 14)

```

```{r N-Grams}
# 
# #Bigrams
# 
# #Analyze and visualize bigrams.
# 
# bigrams <- feedback_cleaned %>%
#   unnest_tokens(bigram, Feedback, token = "ngrams", n = 2)
# 
# clean_bigrams <- bigrams %>%
#   separate(bigram, into = c("word1", "word2"), sep = " ") %>%
#   filter(!word1 %in% stop_words$word,
#          !word2 %in% stop_words$word) %>%
#   unite(bigram, word1, word2, sep = " ")
# 
# bigram_counts <- clean_bigrams %>%
#   count(bigram, sort = TRUE)
# 
# bigram_counts %>%
#   slice_max(n, n = 20) %>%
#   ggplot(aes(x = reorder(bigram, n), y = n)) +
#   geom_col(fill = "pink") +
#   coord_flip() +
#   labs(title = "Top 20 Bigrams in NHS Feedback",
#        x = "Bigrams", y = "Frequency") +
#   theme_minimal(base_size = 14)
# 
# network_bigrams <- bigram_counts %>%
#   filter(n > 5) %>%
#   separate(bigram, c("word1", "word2"), sep = " ") %>%
#   graph_from_data_frame()
# 
# ggraph(network_bigrams, layout = "fr") +
#   geom_edge_link(aes(edge_alpha = n), show.legend = FALSE) +
#   geom_node_point(color = "orange", size = 4) +
#   geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
#   theme_void() +
#   labs(title = "Bigram Network from NHS Feedback")
# 
# #Trigrams
# 
# #Analyze and visualize trigrams.
# 
# trigrams <- feedback_cleaned %>%
#   unnest_tokens(trigram, Feedback, token = "ngrams", n = 3)
# 
# clean_trigrams <- trigrams %>%
#   separate(trigram, into = c("word1", "word2", "word3"), sep = " ") %>%
#   filter(!word1 %in% stop_words$word,
#          !word2 %in% stop_words$word,
#          !word3 %in% stop_words$word) %>%
#   unite(trigram, word1, word2, word3, sep = " ")
# 
# trigram_counts <- clean_trigrams %>%
#   count(trigram, sort = TRUE)
# 
# trigram_counts %>%
#   slice_max(n, n = 20) %>%
#   ggplot(aes(x = reorder(trigram, n), y = n)) +
#   geom_col(fill = "lightblue") +
#   coord_flip() +
#   labs(
#     title = "Top 20 Trigrams in NHS Feedback",
#     x = "Trigrams",
#     y = "Frequency"
#   ) +
#   theme_minimal(base_size = 14)
```

```{r Topic Modeling}

# #Perform LDA to identify topics, using ID from cleaned_tokens.
# 
# word_counts <- cleaned_tokens %>%
#   count(ID, word)
# 
# dtm <- word_counts %>%
#   cast_dtm(document = ID, term = word, value = n)
# 
# lda_model <- LDA(dtm, k = 5, control = list(seed = 123))
# 
# lda_topics <- tidy(lda_model, matrix = "beta")
# 
# top_terms <- lda_topics %>%
#   group_by(topic) %>%
#   slice_max(beta, n = 10) %>%
#   ungroup()
# 
# top_terms %>%
#   mutate(term = reorder_within(term, beta, topic)) %>%
#   ggplot(aes(beta, term, fill = factor(topic))) +
#   geom_col(show.legend = FALSE) +
#   facet_wrap(~ topic, scales = "free") +
#   scale_y_reordered() +
#   labs(title = "Top Terms per Topic in NHS Feedback") +
#   theme_minimal()
# 
# 
# 
# document_topics <- tidy(lda_model, matrix = "gamma")
# ```
# 
# ```{r Assigning Topic Names}
# 
# #Assign descriptiveιασ
# 
# #System: descriptive names to topics and join with feedback data.
# 
# topic_names <- data.frame(
#   topic = 1:5,
#   topic_name = c(
#     "Routine & GP Concerns",
#     "Pain & Symptom",
#     "App & Technical Issues",
#     "Pain Frustrations",
#     "Service Complaints & Prescriptions"
#   )
# )
# 
# assigned_topics <- document_topics %>%
#   group_by(document) %>%
#   slice_max(gamma, n = 1) %>%
#   ungroup() %>%
#   mutate(document = as.integer(document))
# 
# feedback_with_topics <- feedback_cleaned %>%
#   left_join(assigned_topics, by = c("ID" = "document")) %>%
#   left_join(topic_names, by = "topic")
# 
# #Visualizing Topic Distribution
# 
# #Visualize topic distribution overall and by group.
# 
# topic_counts <- feedback_with_topics %>%
#   group_by(topic_name) %>%
#   summarise(count = n()) %>%
#   arrange(desc(count))
# 
# ggplot(topic_counts, aes(x = reorder(topic_name, count), y = count, fill = topic_name)) +
#   geom_col(show.legend = FALSE) +
#   geom_text(aes(label = count), hjust = -0.2, size = 5) +
#   coord_flip() +
#   scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
#   labs(title = "Distribution of Topics in NHS Feedback (n = 350)",
#        x = "Topic", y = "Number of Feedbacks") +
#   theme_minimal(base_size = 14)
# 
# 
# # Topic Distribution by Clinical.Y.N
# topic_counts_by_clinical <- feedback_with_topics %>%
#   group_by(Clinical.Y.N, topic_name) %>%
#   summarise(count = n()) %>%
#   mutate(proportion = count / sum(count))
# 
# ggplot(topic_counts_by_clinical, aes(x = Clinical.Y.N, y = proportion, fill = topic_name)) +
#   geom_col(position = "dodge") +
#   labs(
#     title = "Topic Distribution by Clinical vs. Non-Clinical Feedback",
#     x = "Clinical Status",
#     y = "Proportion",
#     fill = "Topic"
#   ) +
#   theme_minimal()
# 
# # Chi-square test for topic distribution
# topic_table <- table(feedback_with_topics$Clinical.Y.N, feedback_with_topics$topic)
# chisq.test(topic_table)
# 
# # Topic Distribution by Gender (if available)
# if ("Gender" %in% colnames(feedback)) {
#   topic_counts_by_gender <- feedback_with_topics %>%
#     group_by(Gender, topic_name) %>%
#     summarise(count = n()) %>%
#     mutate(proportion = count / sum(count))
# 
#   ggplot(topic_counts_by_gender, aes(x = Gender, y = proportion, fill = topic_name)) +
#     geom_col(position = "dodge") +
#     labs(
#       title = "Topic Distribution by Gender",
#       x = "Gender",
#       y = "Proportion",
#       fill = "Topic"
#     ) +
#     theme_minimal()
# 
#   topic_table_gender <- table(feedback_with_topics$Gender, feedback_with_topics$topic)
#   chisq.test(topic_table_gender)
# }
# 
# ```
# 
# ```{r Model Training}
# 
# # Prepare data for classification.
# 
# model_data <- feedback_cleaned %>%
#   mutate(label = factor(case_when(
#     Clinical.Y.N == "Y" ~ "clinical",
#     Clinical.Y.N == "N" ~ "non_clinical"
#   ))) %>%
#   select(Feedback, label)
# 
# data_split <- initial_split(model_data, prop = 0.8, strata = label)
# train_data <- training(data_split)
# test_data <- testing(data_split)
# ```
# 
# ```{r Text Preprocessing Recipe}
# 
# #Define a recipe for text preprocessing.
# 
# text_recipe <- recipe(label ~ Feedback, data = train_data) %>%
#   step_tokenize(Feedback) %>%
#   step_stopwords(Feedback) %>%
#   step_tokenfilter(Feedback, max_tokens = 500) %>%
#   step_tfidf(Feedback) %>%
#   step_normalize(all_predictors())
# ```
# 
# ```{r Define Models}
# 
# #Specify models for classification.
# 
# nb_model <- naive_Bayes() %>%
#   set_engine("naivebayes")
# 
# log_model <- multinom_reg(penalty = 0) %>%
#   set_engine("glmnet") %>%
#   set_mode("classification")
# 
# rf_model <- rand_forest(trees = 500) %>%
#   set_engine("ranger") %>%
#   set_mode("classification")
# 
# xgb_model <- boost_tree(trees = 500, learn_rate = 0.05) %>%
#   set_engine("xgboost") %>%
#   set_mode("classification")
# ```
# 
# ```{r Model Tuning (XGBoost)}
# 
# #Tune XGBoost hyperparameters.
# xgb_spec <- boost_tree(
#   trees = tune(),
#   tree_depth = tune(),
#   learn_rate = tune()
# ) %>%
#   set_engine("xgboost") %>%
#   set_mode("classification")
# 
# xgb_wf <- workflow() %>%
#   add_recipe(text_recipe) %>%
#   add_model(xgb_spec)
# 
# xgb_grid <- grid_regular(
#   trees(range = c(100, 1000)),
#   tree_depth(range = c(3, 10)),
#   learn_rate(range = c(0.01, 0.1)),
#   levels = 3
# )
# 
# cv_folds <- vfold_cv(train_data, v = 5)
# 
# xgb_tune <- tune_grid(
#   xgb_wf,
#   resamples = cv_folds,
#   grid = xgb_grid,
#   metrics = metric_set(accuracy, roc_auc)
# )
# 
# best_xgb <- select_best(xgb_tune, metric = "roc_auc")
# 
# final_xgb_wf <- finalize_workflow(xgb_wf, best_xgb)
# ```
# 
# ```{r Fit Models}
# 
# #Fit all models, including the tuned XGBoost.
# 
# nb_wf <- workflow() %>% add_recipe(text_recipe) %>% add_model(nb_model)
# log_wf <- workflow() %>% add_recipe(text_recipe) %>% add_model(log_model)
# rf_wf <- workflow() %>% add_recipe(text_recipe) %>% add_model(rf_model)
# final_xgb_fit <- fit(final_xgb_wf, data = train_data)
# 
# nb_fit <- fit(nb_wf, data = train_data)
# log_fit <- fit(log_wf, data = train_data)
# rf_fit <- fit(rf_wf, data = train_data)
# 
# ```
# 
# ```{r Feature Importance}
# 
# #Visualize feature importance for XGBoost.
# xgb_importance <- final_xgb_fit %>%
#   extract_fit_parsnip() %>%
#   vip(num_features = 20) +
#   labs(title = "Feature Importance for XGBoost Model") +
#   theme_minimal()
# 
# print(xgb_importance)
# ```
# 
# ```{r Cross-Validation Metrics}
# # Make sure "clinical" is the positive class
# train_data <- train_data %>% mutate(label = forcats::fct_relevel(label, "clinical"))
# test_data  <- test_data  %>% mutate(label = forcats::fct_relevel(label, "clinical"))
# 
# # Create yardstick metrics with explicit positive class
# prec_m <- yardstick::metric_tweak("precision", yardstick::precision, event_level = "first")
# rec_m  <- yardstick::metric_tweak("recall",    yardstick::recall,    event_level = "first")
# f1_m   <- yardstick::metric_tweak("f_meas",    yardstick::f_meas,    event_level = "first")
# auc_m  <- yardstick::metric_tweak("roc_auc",   yardstick::roc_auc,   event_level = "first")
# 
# cv_metrics <- function(workflow, data, folds = 5) {
#   cv_folds <- vfold_cv(data, v = folds)
#   metrics <- fit_resamples(
#     workflow,
#     resamples = cv_folds,
#     metrics = yardstick::metric_set(
#       yardstick::accuracy,
#       prec_m, rec_m, f1_m, auc_m
#     )
#   ) %>%
#     collect_metrics()
#   return(metrics)
# }
# 
# nb_cv_metrics  <- cv_metrics(nb_wf, train_data)
# log_cv_metrics <- cv_metrics(log_wf, train_data)
# rf_cv_metrics  <- cv_metrics(rf_wf, train_data)
# xgb_cv_metrics <- cv_metrics(final_xgb_wf, train_data)
# 
# all_cv_metrics <- bind_rows(
#   mutate(nb_cv_metrics, model = "Naive Bayes"),
#   mutate(log_cv_metrics, model = "Logistic Regression"),
#   mutate(rf_cv_metrics, model = "Random Forest"),
#   mutate(xgb_cv_metrics, model = "XGBoost")
# )
# 
# print(all_cv_metrics)
# write_csv(all_cv_metrics, "results/cv_metrics.csv")
# 
# ```
# 
# ```{r Confusion Matrix}
# 
# #Evaluate models on the test set.
# 
# get_metrics <- function(model_fit, test_data, model_name) {
#   preds <- predict(model_fit, test_data, type = "prob") %>%
#     bind_cols(predict(model_fit, test_data)) %>%
#     bind_cols(test_data %>% select(label))
#   
#   cm <- conf_mat(preds, truth = label, estimate = .pred_class)
#   
#   cat("\n--- Confusion Matrix for", model_name, "---\n")
#   print(cm)
#   
#   metrics <- preds %>%
#     metrics(truth = label, estimate = .pred_class) %>%
#     bind_rows(preds %>% f_meas(truth = label, estimate = .pred_class))
#   
#   list(preds = preds, metrics = metrics, cm = cm)
# }
# 
# nb_res <- get_metrics(nb_fit, test_data, "Naive Bayes")
# log_res <- get_metrics(log_fit, test_data, "Logistic Regression")
# rf_res <- get_metrics(rf_fit, test_data, "Random Forest")
# xgb_res <- get_metrics(final_xgb_fit, test_data, "XGBoost")
# 
# plot_confusion_matrix <- function(cm, title) {
#   cm_data <- as.data.frame(cm$table)
#   colnames(cm_data) <- c("Truth", "Prediction", "Freq")
#   
#   ggplot(cm_data, aes(x = Prediction, y = Truth, fill = Freq)) +
#     geom_tile() +
#     geom_text(aes(label = Freq), color = "white", size = 6, fontface = "bold") +
#     scale_fill_gradient(low = "#deebf7", high = "#08306b") +
#     ggtitle(title) +
#     theme_minimal(base_size = 16)
# }
# 
# plot_confusion_matrix(nb_res$cm, "Naive Bayes Confusion Matrix")
# plot_confusion_matrix(log_res$cm, "Logistic Regression Confusion Matrix")
# plot_confusion_matrix(rf_res$cm, "Random Forest Confusion Matrix")
# plot_confusion_matrix(xgb_res$cm, "XGBoost Confusion Matrix")
# ```
# 
# ```{r ROC and AUC}
# 
# #Visualize ROC curves and compute AUC.
# 
# get_roc_auc <- function(res, model_name) {
#   roc_points <- roc_curve(res$preds, truth = label, .pred_clinical) %>%
#     mutate(model = model_name)
#   auc_value <- roc_auc(res$preds, truth = label, .pred_clinical) %>%
#     pull(.estimate)
#   list(roc = roc_points, auc = auc_value)
# }
# 
# nb <- get_roc_auc(nb_res, "Naive Bayes")
# log <- get_roc_auc(log_res, "Logistic Regression")
# rf <- get_roc_auc(rf_res, "Random Forest")
# xgb <- get_roc_auc(xgb_res, "XGBoost")
# 
# roc_data <- bind_rows(nb$roc, log$roc, rf$roc, xgb$roc)
# 
# auc_labels <- c(
#   paste0("Naive Bayes (AUC=", round(nb$auc, 3), ")"),
#   paste0("Logistic Regression (AUC=", round(log$auc, 3), ")"),
#   paste0("Random Forest (AUC=", round(rf$auc, 3), ")"),
#   paste0("XGBoost (AUC=", round(xgb$auc, 3), ")")
# )
# 
# roc_data$model <- factor(
#   roc_data$model,
#   levels = c("Naive Bayes", "Logistic Regression", "Random Forest", "XGBoost"),
#   labels = auc_labels
# )
# 
# cols <- setNames(c("red", "blue", "green", "purple"), auc_labels)
# 
# ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity, color = model)) +
#   geom_path(size = 1.2) +
#   geom_abline(linetype = "dashed") +
#   labs(
#     title = "ROC Curves with AUC for All Models",
#     x = "False Positive Rate",
#     y = "True Positive Rate",
#     color = "Model (AUC)"
#   ) +
#   theme_minimal() +
#   scale_color_manual(values = cols)
# 
# ```
# 
# ```{r Model Metrics}
# # Ensure the positive class is first (so event_level = "first" means "clinical")
# train_data <- train_data %>% mutate(label = forcats::fct_relevel(label, "clinical"))
# test_data  <- test_data  %>% mutate(label = forcats::fct_relevel(label, "clinical"))
# 
# # Use yardstick metrics explicitly to avoid caret masking
# prec_m <- yardstick::metric_tweak("precision", yardstick::precision, event_level = "first")
# rec_m  <- yardstick::metric_tweak("recall",    yardstick::recall,    event_level = "first")
# f1_m   <- yardstick::metric_tweak("f_meas",    yardstick::f_meas,    event_level = "first")
# 
# all_metrics_set <- yardstick::metric_set(
#   yardstick::accuracy,
#   prec_m, rec_m, f1_m
# )
# 
# get_model_metrics <- function(model_fit, test_data, model_name) {
#   preds <- predict(model_fit, test_data, type = "prob") %>%
#     bind_cols(predict(model_fit, test_data)) %>%   # adds .pred_class
#     bind_cols(test_data %>% dplyr::select(label))
# 
#   metrics <- all_metrics_set(preds, truth = label, estimate = .pred_class) %>%
#     dplyr::mutate(model = model_name)
# 
#   return(metrics)
# }
# 
# nb_metrics  <- get_model_metrics(nb_fit,         test_data, "Naive Bayes")
# log_metrics <- get_model_metrics(log_fit,        test_data, "Logistic Regression")
# rf_metrics  <- get_model_metrics(rf_fit,         test_data, "Random Forest")
# xgb_metrics <- get_model_metrics(final_xgb_fit,  test_data, "XGBoost")
# 
# all_metrics <- dplyr::bind_rows(nb_metrics, log_metrics, rf_metrics, xgb_metrics)
# print(all_metrics)
# readr::write_csv(all_metrics, "results/model_metrics.csv")
# 
# # Save the tuned XGBoost model
# saveRDS(final_xgb_fit, "results/tuned_xgboost_model.rds")
# 
# ```
# 
# ```{r Shiny App}
# # app.R
# 
# # ---- Libraries (must be loaded inside the app file) ----
# library(shiny)
# library(dplyr)
# library(readr)
# library(ggplot2)
# library(tibble)
# library(stringr)
# library(wordcloud)
# library(RColorBrewer)
# library(tidytext)   # for unnest_tokens and stop_words
# library(workflows)  # for workflow objects
# library(parsnip)    # for predict() via tidymodels models
# library(hardhat)    # sometimes needed for preprocessing in workflows
# 
# # ---- Load the trained workflow/model ----
# # Make sure this path exists relative to app.R
# model <- readRDS("results/tuned_xgboost_model.rds")
# 
# # ---- UI ----
# ui <- fluidPage(
#   tags$head(
#     tags$style(HTML("
#       body {
#         background-image: url('images.png');   /* file placed in /www */
#         background-size: cover;
#         background-repeat: no-repeat;
#         background-attachment: fixed;
#         background-position: center;
#         color: #2c3e50;
#       }
#       .overlay {
#         background-color: rgba(255, 255, 255, 0.85);
#         padding: 30px;
#         border-radius: 10px;
#         max-width: 900px;
#         margin: 50px auto;
#       }
#       .title-text { color: #005EB8; font-size: 32px; font-weight: bold; margin-top: 10px; text-align: center; }
#       .sub-title { color: #B03060; font-size: 18px; text-align: center; }
#       .result-box { font-size: 22px; font-weight: bold; padding: 15px; border-radius: 8px; margin-top: 20px; text-align: center; }
#       #predict { width: 220px; height: 50px; font-size: 18px; }
#       #feedback { font-size: 16px; }
#     "))
#   ),
#   div(class = "overlay",
#       div(class = "title-text", "NHS Feedback Classifier"),
#       div(class = "sub-title", "Powered by Sheffield Hallam University"),
#       textAreaInput("feedback", "Enter Patient Feedback:", "", width = "100%", height = "150px"),
#       br(),
#       actionButton("predict", "Predict", class = "btn btn-primary btn-lg"),
#       uiOutput("prediction_output"),
#       plotOutput("wordcloud"),
#       hr(),
#       h4("How it Works"),
#       p("Enter patient feedback and click Predict. The model will classify whether it requires clinical review."),
#       h3("About the Model"),
#       p("This application uses a tuned XGBoost model trained on NHS patient feedback.")
#   )
# )
# 
# # ---- Server ----
# server <- function(input, output, session) {
# 
#   observeEvent(input$predict, {
#     # Basic validation
#     req(input$feedback)
#     txt <- trimws(input$feedback)
#     validate(need(nchar(txt) > 0, "Please enter valid feedback."))
# 
#     # Prepare new data frame with the exact column name used in training
#     new_data <- tibble(Feedback = txt)
# 
#     # Predict with the saved workflow; it contains the recipe, so raw text is fine
#     probs <- predict(model, new_data, type = "prob")
#     classes <- predict(model, new_data, type = "class")
# 
#     prediction <- bind_cols(probs, classes)  # adds .pred_class
# 
#     # Figure out the confidence safely (handles any level names)
#     # Grab all probability columns that start with .pred_
#     prob_cols <- dplyr::select(prediction, dplyr::starts_with(".pred_"))
#     confidence <- round(max(as.numeric(prob_cols[1, ])) * 100, 2)
# 
#     pred_class <- prediction$.pred_class %>% as.character()
# 
#     output$prediction_output <- renderUI({
#       color <- ifelse(pred_class == "clinical", "#e74c3c", "#2ecc71")
#       HTML(
#         sprintf(
#           "<div class='result-box' style='background-color:%s; color:white;'>
#              Prediction: %s (Confidence: %s%%)
#            </div>",
#           color, pred_class, confidence
#         )
#       )
#     })
# 
#     # Word cloud (guard against empty after stopword removal)
#     output$wordcloud <- renderPlot({
#       words <- tibble(text = txt) %>%
#         unnest_tokens(word, text) %>%
#         anti_join(tidytext::stop_words, by = "word") %>%
#         count(word, sort = TRUE)
# 
#       validate(need(nrow(words) > 0, "Not enough meaningful words to plot a word cloud."))
# 
#       wordcloud(
#         words = words$word,
#         freq = words$n,
#         max.words = 50,
#         colors = brewer.pal(8, "Dark2"),
#         random.order = FALSE
#       )
#     })
#   })
# }
# 
# # ---- Run the app ----
# shinyApp(ui = ui, server = server)
```
